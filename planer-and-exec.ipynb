{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"Let's first understand the problem and devise a plan to solve the problem.\"\n",
    "    \" Please output the plan starting with the header 'Plan:' \"\n",
    "    \"and then followed by a numbered list of steps. \"\n",
    "    \"Please make the plan the minimum number of steps required \"\n",
    "    \"to accurately complete the task. If the task is a question, \"\n",
    "    \"the final step should almost always be 'Given the above steps taken, \"\n",
    "    \"please respond to the users original question'. \"\n",
    "    \"At the end of your plan, say '<END_OF_PLAN>'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "def parse(text: str):\n",
    "        steps = [f\"Step(value={v})\" for v in re.split(\"\\n\\s*\\d+\\. \", text)[1:]]\n",
    "        return f\"steps={steps}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"how to improve spoken english?\"\n",
    "stop=[\"<END_OF_PLAN>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Listen to English audio content regularly.', 'Practice speaking English with a native speaker or someone who is fluent in English.', 'Read English books, newspapers, and articles to improve vocabulary and grammar.', 'Record yourself speaking and listen to it to identify areas of improvement.', 'Join an English speaking club or group to practice speaking with others.', 'Watch English movies and TV shows with subtitles to improve pronunciation and comprehension.', \"Don't be afraid to make mistakes and keep practicing consistently.\\n\\nGiven the above steps taken, please respond to the user's original question.\"]\n"
     ]
    }
   ],
   "source": [
    "llm_response = llm_chain.run(input=input, stop=stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps=['Step(value=Listen to English audio content regularly.)', 'Step(value=Practice speaking English with a native speaker or someone who is fluent in English.)', 'Step(value=Read English books, newspapers, and articles to improve vocabulary and grammar.)', 'Step(value=Record yourself speaking and listen to it to identify areas of improvement.)', 'Step(value=Join an English speaking club or group to practice speaking with others.)', 'Step(value=Watch English movies and TV shows with subtitles to improve pronunciation and comprehension.)', \"Step(value=Don't be afraid to make mistakes and keep practicing consistently.\\n\\nGiven the above steps taken, please respond to the user's original question.)\"]\n"
     ]
    }
   ],
   "source": [
    "response = parse(llm_response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
